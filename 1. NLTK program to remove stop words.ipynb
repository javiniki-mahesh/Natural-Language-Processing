{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ce9e19",
   "metadata": {},
   "source": [
    "## 1. Write a Python NLTK program to remove stop words from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d0ab596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2e8a5",
   "metadata": {},
   "source": [
    "Complete function to remove stop words from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31112f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "010d2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words after removing of stop words: \n",
      " ['As', 'enthusiastic', 'data', 'science', 'student,', 'I', 'constantly', 'lookout', 'new', 'techniques', 'tools', 'add', 'data', 'analysis', 'toolkit.', 'One', 'area', 'always', 'intrigued', 'natural', 'language', 'processing', '(NLP),', 'study', 'computers', 'understand,', 'interpret,', 'generate', 'human', 'language.', 'NLP', 'fascinating', 'field', 'becoming', 'increasingly', 'important', \"today's\", 'digital', 'age.', 'With', 'explosion', 'data', 'growth', 'social', 'media,', 'huge', 'amount', 'text', 'data', 'available', 'used', 'gain', 'insights', \"people's\", 'opinions,', 'emotions,', 'behaviors.', 'NLP', 'provides', 'tools', 'techniques', 'analyze', 'data', 'extract', 'valuable', 'insights', 'inform', 'decision-making', 'various', 'fields', 'marketing,', 'healthcare,', 'finance.', 'As', 'data', 'science', 'student,', 'I', 'learning', 'different', 'techniques', 'used', 'NLP,', 'tokenization,', 'stemming,', 'lemmatization.', 'Tokenization', 'involves', 'breaking', 'text', 'individual', 'words', 'tokens,', 'analyzed', 'processed', 'further.', 'Stemming', 'lemmatization', 'techniques', 'used', 'reduce', 'words', 'root', 'form,', 'help', 'reduce', 'complexity', 'text', 'data', 'improve', 'accuracy', 'analysis.', 'One', 'exciting', 'aspects', 'NLP', 'ability', 'use', 'machine', 'learning', 'algorithms', 'automatically', 'classify', 'text', 'data', 'different', 'categories', 'perform', 'sentiment', 'analysis', 'determine', 'emotional', 'tone', 'piece', 'text.', 'These', 'techniques', 'used', 'build', 'powerful', 'predictive', 'models', 'help', 'businesses', 'understand', 'customers', 'better', 'make', 'informed', 'decisions.', 'As', 'I', 'continue', 'journey', 'data', 'science', 'student,', 'I', 'excited', 'learn', 'NLP', 'apply', 'techniques', 'real-world', 'problems.', 'I', 'believe', 'NLP', 'play', 'increasingly', 'important', 'role', 'data', 'analysis', 'decision-making', 'years', 'come,', 'I', 'eager', 'part', 'exciting', 'field.']\n"
     ]
    }
   ],
   "source": [
    "def  remove_stopwords(text):\n",
    "    \"\"\"Function to remove stop words\"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    text_words = text.split()\n",
    "    non_stop_words_in_text = [i for i in text_words if (i not in stop_words)]\n",
    "    print(\"Words after removing of stop words: \\n\",non_stop_words_in_text)\n",
    "\n",
    "text = \"\"\"As an enthusiastic data science student, I am constantly on the lookout for new techniques and tools to add to my data analysis toolkit. One area that has always intrigued me is natural language processing (NLP), which is the study of how computers can understand, interpret, and generate human language.\n",
    "\n",
    "NLP is a fascinating field that is becoming increasingly important in today's digital age. With the explosion of data and the growth of social media, there is a huge amount of text data available that can be used to gain insights into people's opinions, emotions, and behaviors. NLP provides the tools and techniques to analyze this data and extract valuable insights that can inform decision-making in various fields such as marketing, healthcare, and finance.\n",
    "\n",
    "As a data science student, I have been learning about the different techniques used in NLP, such as tokenization, stemming, and lemmatization. Tokenization involves breaking up a text into individual words or tokens, which can then be analyzed and processed further. Stemming and lemmatization are techniques used to reduce words to their root form, which can help to reduce the complexity of the text data and improve the accuracy of the analysis.\n",
    "\n",
    "One of the most exciting aspects of NLP is the ability to use machine learning algorithms to automatically classify text data into different categories or to perform sentiment analysis to determine the emotional tone of a piece of text. These techniques can be used to build powerful predictive models that can help businesses to understand their customers better and to make more informed decisions.\n",
    "\n",
    "As I continue my journey as a data science student, I am excited to learn more about NLP and to apply these techniques to real-world problems. I believe that NLP will play an increasingly important role in data analysis and decision-making in the years to come, and I am eager to be a part of this exciting field.\"\"\"\n",
    "remove_stopwords(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b7f9c",
   "metadata": {},
   "source": [
    "More detailed content is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "472aaf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of stopwords are : \n",
      " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "Number of stop words:  179\n",
      "Sorted list of stop words ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(\"The list of stopwords are : \\n\", stop_words)\n",
    "print(\"Number of stop words: \",len(stop_words))\n",
    "print(\"Sorted list of stop words\",sorted(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81e4ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"As an enthusiastic data science student, I am constantly on the lookout for new techniques and tools to add to my data analysis toolkit. One area that has always intrigued me is natural language processing (NLP), which is the study of how computers can understand, interpret, and generate human language.\n",
    "\n",
    "NLP is a fascinating field that is becoming increasingly important in today's digital age. With the explosion of data and the growth of social media, there is a huge amount of text data available that can be used to gain insights into people's opinions, emotions, and behaviors. NLP provides the tools and techniques to analyze this data and extract valuable insights that can inform decision-making in various fields such as marketing, healthcare, and finance.\n",
    "\n",
    "As a data science student, I have been learning about the different techniques used in NLP, such as tokenization, stemming, and lemmatization. Tokenization involves breaking up a text into individual words or tokens, which can then be analyzed and processed further. Stemming and lemmatization are techniques used to reduce words to their root form, which can help to reduce the complexity of the text data and improve the accuracy of the analysis.\n",
    "\n",
    "One of the most exciting aspects of NLP is the ability to use machine learning algorithms to automatically classify text data into different categories or to perform sentiment analysis to determine the emotional tone of a piece of text. These techniques can be used to build powerful predictive models that can help businesses to understand their customers better and to make more informed decisions.\n",
    "\n",
    "As I continue my journey as a data science student, I am excited to learn more about NLP and to apply these techniques to real-world problems. I believe that NLP will play an increasingly important role in data analysis and decision-making in the years to come, and I am eager to be a part of this exciting field.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6844128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in text:  ['As', 'an', 'enthusiastic', 'data', 'science', 'student,', 'I', 'am', 'constantly', 'on', 'the', 'lookout', 'for', 'new', 'techniques', 'and', 'tools', 'to', 'add', 'to', 'my', 'data', 'analysis', 'toolkit.', 'One', 'area', 'that', 'has', 'always', 'intrigued', 'me', 'is', 'natural', 'language', 'processing', '(NLP),', 'which', 'is', 'the', 'study', 'of', 'how', 'computers', 'can', 'understand,', 'interpret,', 'and', 'generate', 'human', 'language.', 'NLP', 'is', 'a', 'fascinating', 'field', 'that', 'is', 'becoming', 'increasingly', 'important', 'in', \"today's\", 'digital', 'age.', 'With', 'the', 'explosion', 'of', 'data', 'and', 'the', 'growth', 'of', 'social', 'media,', 'there', 'is', 'a', 'huge', 'amount', 'of', 'text', 'data', 'available', 'that', 'can', 'be', 'used', 'to', 'gain', 'insights', 'into', \"people's\", 'opinions,', 'emotions,', 'and', 'behaviors.', 'NLP', 'provides', 'the', 'tools', 'and', 'techniques', 'to', 'analyze', 'this', 'data', 'and', 'extract', 'valuable', 'insights', 'that', 'can', 'inform', 'decision-making', 'in', 'various', 'fields', 'such', 'as', 'marketing,', 'healthcare,', 'and', 'finance.', 'As', 'a', 'data', 'science', 'student,', 'I', 'have', 'been', 'learning', 'about', 'the', 'different', 'techniques', 'used', 'in', 'NLP,', 'such', 'as', 'tokenization,', 'stemming,', 'and', 'lemmatization.', 'Tokenization', 'involves', 'breaking', 'up', 'a', 'text', 'into', 'individual', 'words', 'or', 'tokens,', 'which', 'can', 'then', 'be', 'analyzed', 'and', 'processed', 'further.', 'Stemming', 'and', 'lemmatization', 'are', 'techniques', 'used', 'to', 'reduce', 'words', 'to', 'their', 'root', 'form,', 'which', 'can', 'help', 'to', 'reduce', 'the', 'complexity', 'of', 'the', 'text', 'data', 'and', 'improve', 'the', 'accuracy', 'of', 'the', 'analysis.', 'One', 'of', 'the', 'most', 'exciting', 'aspects', 'of', 'NLP', 'is', 'the', 'ability', 'to', 'use', 'machine', 'learning', 'algorithms', 'to', 'automatically', 'classify', 'text', 'data', 'into', 'different', 'categories', 'or', 'to', 'perform', 'sentiment', 'analysis', 'to', 'determine', 'the', 'emotional', 'tone', 'of', 'a', 'piece', 'of', 'text.', 'These', 'techniques', 'can', 'be', 'used', 'to', 'build', 'powerful', 'predictive', 'models', 'that', 'can', 'help', 'businesses', 'to', 'understand', 'their', 'customers', 'better', 'and', 'to', 'make', 'more', 'informed', 'decisions.', 'As', 'I', 'continue', 'my', 'journey', 'as', 'a', 'data', 'science', 'student,', 'I', 'am', 'excited', 'to', 'learn', 'more', 'about', 'NLP', 'and', 'to', 'apply', 'these', 'techniques', 'to', 'real-world', 'problems.', 'I', 'believe', 'that', 'NLP', 'will', 'play', 'an', 'increasingly', 'important', 'role', 'in', 'data', 'analysis', 'and', 'decision-making', 'in', 'the', 'years', 'to', 'come,', 'and', 'I', 'am', 'eager', 'to', 'be', 'a', 'part', 'of', 'this', 'exciting', 'field.']\n",
      "\n",
      "\n",
      "Number of words in text:  318\n"
     ]
    }
   ],
   "source": [
    "text_words = text.split()\n",
    "print(\"Words in text: \",text_words)\n",
    "print(\"\\n\\nNumber of words in text: \",len(text_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8b5c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'enthusiastic', 'data', 'science', 'student,', 'I', 'constantly', 'lookout', 'new', 'techniques', 'tools', 'add', 'data', 'analysis', 'toolkit.', 'One', 'area', 'always', 'intrigued', 'natural', 'language', 'processing', '(NLP),', 'study', 'computers', 'understand,', 'interpret,', 'generate', 'human', 'language.', 'NLP', 'fascinating', 'field', 'becoming', 'increasingly', 'important', \"today's\", 'digital', 'age.', 'With', 'explosion', 'data', 'growth', 'social', 'media,', 'huge', 'amount', 'text', 'data', 'available', 'used', 'gain', 'insights', \"people's\", 'opinions,', 'emotions,', 'behaviors.', 'NLP', 'provides', 'tools', 'techniques', 'analyze', 'data', 'extract', 'valuable', 'insights', 'inform', 'decision-making', 'various', 'fields', 'marketing,', 'healthcare,', 'finance.', 'As', 'data', 'science', 'student,', 'I', 'learning', 'different', 'techniques', 'used', 'NLP,', 'tokenization,', 'stemming,', 'lemmatization.', 'Tokenization', 'involves', 'breaking', 'text', 'individual', 'words', 'tokens,', 'analyzed', 'processed', 'further.', 'Stemming', 'lemmatization', 'techniques', 'used', 'reduce', 'words', 'root', 'form,', 'help', 'reduce', 'complexity', 'text', 'data', 'improve', 'accuracy', 'analysis.', 'One', 'exciting', 'aspects', 'NLP', 'ability', 'use', 'machine', 'learning', 'algorithms', 'automatically', 'classify', 'text', 'data', 'different', 'categories', 'perform', 'sentiment', 'analysis', 'determine', 'emotional', 'tone', 'piece', 'text.', 'These', 'techniques', 'used', 'build', 'powerful', 'predictive', 'models', 'help', 'businesses', 'understand', 'customers', 'better', 'make', 'informed', 'decisions.', 'As', 'I', 'continue', 'journey', 'data', 'science', 'student,', 'I', 'excited', 'learn', 'NLP', 'apply', 'techniques', 'real-world', 'problems.', 'I', 'believe', 'NLP', 'play', 'increasingly', 'important', 'role', 'data', 'analysis', 'decision-making', 'years', 'come,', 'I', 'eager', 'part', 'exciting', 'field.']\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in text_words:\n",
    "    if i not in stop_words:\n",
    "        l.append(i)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2248a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words do not fall under stop words present in text : \n",
      " ['As', 'enthusiastic', 'data', 'science', 'student,', 'I', 'constantly', 'lookout', 'new', 'techniques', 'tools', 'add', 'data', 'analysis', 'toolkit.', 'One', 'area', 'always', 'intrigued', 'natural', 'language', 'processing', '(NLP),', 'study', 'computers', 'understand,', 'interpret,', 'generate', 'human', 'language.', 'NLP', 'fascinating', 'field', 'becoming', 'increasingly', 'important', \"today's\", 'digital', 'age.', 'With', 'explosion', 'data', 'growth', 'social', 'media,', 'huge', 'amount', 'text', 'data', 'available', 'used', 'gain', 'insights', \"people's\", 'opinions,', 'emotions,', 'behaviors.', 'NLP', 'provides', 'tools', 'techniques', 'analyze', 'data', 'extract', 'valuable', 'insights', 'inform', 'decision-making', 'various', 'fields', 'marketing,', 'healthcare,', 'finance.', 'As', 'data', 'science', 'student,', 'I', 'learning', 'different', 'techniques', 'used', 'NLP,', 'tokenization,', 'stemming,', 'lemmatization.', 'Tokenization', 'involves', 'breaking', 'text', 'individual', 'words', 'tokens,', 'analyzed', 'processed', 'further.', 'Stemming', 'lemmatization', 'techniques', 'used', 'reduce', 'words', 'root', 'form,', 'help', 'reduce', 'complexity', 'text', 'data', 'improve', 'accuracy', 'analysis.', 'One', 'exciting', 'aspects', 'NLP', 'ability', 'use', 'machine', 'learning', 'algorithms', 'automatically', 'classify', 'text', 'data', 'different', 'categories', 'perform', 'sentiment', 'analysis', 'determine', 'emotional', 'tone', 'piece', 'text.', 'These', 'techniques', 'used', 'build', 'powerful', 'predictive', 'models', 'help', 'businesses', 'understand', 'customers', 'better', 'make', 'informed', 'decisions.', 'As', 'I', 'continue', 'journey', 'data', 'science', 'student,', 'I', 'excited', 'learn', 'NLP', 'apply', 'techniques', 'real-world', 'problems.', 'I', 'believe', 'NLP', 'play', 'increasingly', 'important', 'role', 'data', 'analysis', 'decision-making', 'years', 'come,', 'I', 'eager', 'part', 'exciting', 'field.']\n",
      "\n",
      "Number of words do not fall under stop words present in text :  182\n",
      "\n",
      "Unique words do not fall under stop words present in text : \n",
      " {'businesses', 'ability', 'finance.', 'part', 'techniques', 'lemmatization.', 'use', 'various', 'age.', 'perform', 'come,', 'breaking', 'play', 'healthcare,', 'aspects', 'interpret,', 'better', 'analysis', 'study', 'gain', 'journey', 'digital', 'different', 'accuracy', 'increasingly', 'tone', 'lookout', 'data', 'growth', 'field', 'computers', 'generate', 'stemming,', 'form,', 'make', 'processing', 'text', 'machine', 'help', 'build', 'models', 'tools', 'believe', 'huge', 'customers', 'enthusiastic', 'powerful', 'further.', 'science', \"today's\", 'excited', 'continue', 'marketing,', 'categories', 'automatically', 'inform', 'algorithms', 'piece', 'Stemming', 'learning', 'important', 'analyzed', 'improve', 'analysis.', 'decisions.', 'amount', 'analyze', \"people's\", 'role', 'I', 'determine', 'student,', 'natural', 'root', 'informed', 'fascinating', 'becoming', 'complexity', 'One', 'emotions,', 'opinions,', 'media,', 'extract', 'As', 'provides', 'learn', 'emotional', 'fields', 'apply', 'understand', 'always', 'With', 'tokens,', 'understand,', 'processed', 'decision-making', 'reduce', 'intrigued', 'problems.', 'explosion', 'lemmatization', 'Tokenization', 'new', 'valuable', 'classify', 'tokenization,', 'toolkit.', 'human', 'NLP', 'NLP,', 'insights', 'constantly', 'exciting', 'language', 'available', 'text.', 'behaviors.', 'social', 'area', 'involves', 'individual', 'These', 'add', 'words', 'sentiment', '(NLP),', 'language.', 'used', 'predictive', 'years', 'field.', 'real-world', 'eager'}\n",
      "\n",
      "Number of unique words do not fall under stop words present in text :  133\n"
     ]
    }
   ],
   "source": [
    "non_stop_words_in_text = [i for i in text_words if (i not in stop_words)]\n",
    "print(\"Words do not fall under stop words present in text : \\n\",non_stop_words_in_text)\n",
    "print(\"\\nNumber of words do not fall under stop words present in text : \",len(non_stop_words_in_text))\n",
    "\n",
    "print(\"\\nUnique words do not fall under stop words present in text : \\n\",set(non_stop_words_in_text))\n",
    "print(\"\\nNumber of unique words do not fall under stop words present in text : \",len(set(non_stop_words_in_text)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "acb6c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stop words present in text : \n",
      " ['an', 'am', 'on', 'the', 'for', 'and', 'to', 'to', 'my', 'that', 'has', 'me', 'is', 'which', 'is', 'the', 'of', 'how', 'can', 'and', 'is', 'a', 'that', 'is', 'in', 'the', 'of', 'and', 'the', 'of', 'there', 'is', 'a', 'of', 'that', 'can', 'be', 'to', 'into', 'and', 'the', 'and', 'to', 'this', 'and', 'that', 'can', 'in', 'such', 'as', 'and', 'a', 'have', 'been', 'about', 'the', 'in', 'such', 'as', 'and', 'up', 'a', 'into', 'or', 'which', 'can', 'then', 'be', 'and', 'and', 'are', 'to', 'to', 'their', 'which', 'can', 'to', 'the', 'of', 'the', 'and', 'the', 'of', 'the', 'of', 'the', 'most', 'of', 'is', 'the', 'to', 'to', 'into', 'or', 'to', 'to', 'the', 'of', 'a', 'of', 'can', 'be', 'to', 'that', 'can', 'to', 'their', 'and', 'to', 'more', 'my', 'as', 'a', 'am', 'to', 'more', 'about', 'and', 'to', 'these', 'to', 'that', 'will', 'an', 'in', 'and', 'in', 'the', 'to', 'and', 'am', 'to', 'be', 'a', 'of', 'this']\n",
      "\n",
      "Number of stop words present in text :  136\n",
      "\n",
      "List of unique stop words present in text : \n",
      " {'been', 'their', 'is', 'of', 'which', 'most', 'for', 'into', 'an', 'are', 'then', 'the', 'will', 'in', 'how', 'can', 'to', 'that', 'as', 'be', 'these', 'up', 'have', 'or', 'there', 'such', 'more', 'me', 'this', 'about', 'has', 'my', 'and', 'am', 'a', 'on'}\n",
      "\n",
      "Number of unique stop words present in text :  36\n"
     ]
    }
   ],
   "source": [
    "stop_words_in_text = [word for word in text_words if word in stop_words]\n",
    "print(\"List of stop words present in text : \\n\",stop_words_in_text)\n",
    "print(\"\\nNumber of stop words present in text : \",len(stop_words_in_text))\n",
    "print(\"\\nList of unique stop words present in text : \\n\",set(stop_words_in_text))\n",
    "print(\"\\nNumber of unique stop words present in text : \",len(set(stop_words_in_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
